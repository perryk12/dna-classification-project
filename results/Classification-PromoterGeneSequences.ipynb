{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMSE 410 Project\n",
    "#### Katherine Perry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will go through the kaggle tutorial to load in data from UCI Machine Learning Repository that has 106 DNA sequences, with 57 sequential nucleotides  each. Then I will analyze the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/bulentsiyah/classifying-dna-sequences-markov-models-knn-svm/execution\n",
    "# To make sure all of the correct libraries are installed, import each module and print the version number\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class                                                       +\n",
      "id                                                        S10\n",
      "Sequence    \\t\\ttactagcaatacgcttgcgttcggtggttaagtatgtataat...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# import the uci Molecular Biology (Promoter Gene Sequences) Data Set\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/molecular-biology/promoter-gene-sequences/promoters.data'\n",
    "names = ['Class', 'id', 'Sequence']\n",
    "data = pd.read_csv(url, names = names)\n",
    "print(data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'a', 'c', 't', 'a', 'g', 'c', 'a', 'a', 't', 'a', 'c', 'g', 'c', 't', 't', 'g', 'c', 'g', 't', 't', 'c', 'g', 'g', 't', 'g', 'g', 't', 't', 'a', 'a', 'g', 't', 'a', 't', 'g', 't', 'a', 't', 'a', 'a', 't', 'g', 'c', 'g', 'c', 'g', 'g', 'g', 'c', 't', 't', 'g', 't', 'c', 'g', 't', '+']\n"
     ]
    }
   ],
   "source": [
    "classes = data.loc[:, 'Class']\n",
    "# generate list of DNA sequences\n",
    "sequences = list(data.loc[:, 'Sequence'])\n",
    "dataset = {}\n",
    "\n",
    "# loop through sequences and split into individual nucleotides\n",
    "for i, seq in enumerate(sequences):\n",
    "    \n",
    "    # split into nucleotides, remove tab characters\n",
    "    nucleotides = list(seq)\n",
    "    nucleotides = [x for x in nucleotides if x != '\\t']\n",
    "    \n",
    "    # append class assignment\n",
    "    nucleotides.append(classes[i])\n",
    "    \n",
    "    # add to dataset\n",
    "    dataset[i] = nucleotides\n",
    "    \n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>t</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9  ...   48   49   50  \\\n",
       "count   106  106  106  106  106  106  106  106  106  106  ...  106  106  106   \n",
       "unique    4    4    4    4    4    4    4    4    4    4  ...    4    4    4   \n",
       "top       t    a    a    c    a    a    a    a    a    a  ...    c    c    c   \n",
       "freq     38   34   30   30   36   42   38   34   33   36  ...   36   42   31   \n",
       "\n",
       "         51   52   53   54   55   56 Class  \n",
       "count   106  106  106  106  106  106   106  \n",
       "unique    4    4    4    4    4    4     2  \n",
       "top       t    t    c    c    c    t     -  \n",
       "freq     33   35   32   29   29   34    53  \n",
       "\n",
       "[4 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn dataset into pandas DataFrame\n",
    "dframe = pd.DataFrame(dataset)\n",
    "# transpose the DataFrame\n",
    "df = dframe.transpose()\n",
    "# for clarity, lets rename the last dataframe column to class\n",
    "df.rename(columns = {57: 'Class'}, inplace = True) \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2     3     4     5     6     7     8     9  ...    48  \\\n",
      "t  38.0  26.0  27.0  26.0  22.0  24.0  30.0  32.0  32.0  28.0  ...  21.0   \n",
      "c  27.0  22.0  21.0  30.0  19.0  18.0  21.0  20.0  22.0  22.0  ...  36.0   \n",
      "a  26.0  34.0  30.0  22.0  36.0  42.0  38.0  34.0  33.0  36.0  ...  23.0   \n",
      "g  15.0  24.0  28.0  28.0  29.0  22.0  17.0  20.0  19.0  20.0  ...  26.0   \n",
      "-   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "+   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "\n",
      "     49    50    51    52    53    54    55    56  Class  \n",
      "t  22.0  23.0  33.0  35.0  30.0  23.0  29.0  34.0    NaN  \n",
      "c  42.0  31.0  32.0  21.0  32.0  29.0  29.0  17.0    NaN  \n",
      "a  24.0  28.0  27.0  25.0  22.0  26.0  24.0  27.0    NaN  \n",
      "g  18.0  24.0  14.0  25.0  22.0  28.0  24.0  28.0    NaN  \n",
      "-   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   53.0  \n",
      "+   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   53.0  \n",
      "\n",
      "[6 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# desribe does not tell us enough information since the attributes are text. Lets record value counts for each sequence\n",
    "series = []\n",
    "for name in df.columns:\n",
    "    series.append(df[name].value_counts())\n",
    "    \n",
    "info = pd.DataFrame(series)\n",
    "details = info.transpose()\n",
    "print(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_a</th>\n",
       "      <th>0_c</th>\n",
       "      <th>0_g</th>\n",
       "      <th>0_t</th>\n",
       "      <th>1_a</th>\n",
       "      <th>1_c</th>\n",
       "      <th>1_g</th>\n",
       "      <th>1_t</th>\n",
       "      <th>2_a</th>\n",
       "      <th>2_c</th>\n",
       "      <th>...</th>\n",
       "      <th>55_a</th>\n",
       "      <th>55_c</th>\n",
       "      <th>55_g</th>\n",
       "      <th>55_t</th>\n",
       "      <th>56_a</th>\n",
       "      <th>56_c</th>\n",
       "      <th>56_g</th>\n",
       "      <th>56_t</th>\n",
       "      <th>Class_+</th>\n",
       "      <th>Class_-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_a  0_c  0_g  0_t  1_a  1_c  1_g  1_t  2_a  2_c  ...  55_a  55_c  55_g  \\\n",
       "0    0    0    0    1    1    0    0    0    0    1  ...     0     0     1   \n",
       "1    0    0    0    1    0    0    1    0    0    1  ...     1     0     0   \n",
       "2    0    0    1    0    0    0    0    1    1    0  ...     0     1     0   \n",
       "3    1    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
       "4    0    0    0    1    0    1    0    0    0    0  ...     1     0     0   \n",
       "\n",
       "   55_t  56_a  56_c  56_g  56_t  Class_+  Class_-  \n",
       "0     0     0     0     0     1        1        0  \n",
       "1     0     1     0     0     0        1        0  \n",
       "2     0     0     0     1     0        1        0  \n",
       "3     1     0     1     0     0        1        0  \n",
       "4     0     0     0     1     0        1        0  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unfortunately, we can't run machine learning algorithms on the data in 'String' formats. As a result, we need to switch\n",
    "# it to numerical data. This can easily be accomplished using the pd.get_dummies() function\n",
    "numerical_df = pd.get_dummies(df)\n",
    "numerical_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0_a  0_c  0_g  0_t  1_a  1_c  1_g  1_t  2_a  2_c  ...  54_t  55_a  55_c  \\\n",
      "0    0    0    0    1    1    0    0    0    0    1  ...     0     0     0   \n",
      "1    0    0    0    1    0    0    1    0    0    1  ...     0     1     0   \n",
      "2    0    0    1    0    0    0    0    1    1    0  ...     0     0     1   \n",
      "3    1    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
      "4    0    0    0    1    0    1    0    0    0    0  ...     1     1     0   \n",
      "\n",
      "   55_g  55_t  56_a  56_c  56_g  56_t  Class  \n",
      "0     1     0     0     0     0     1      1  \n",
      "1     0     0     1     0     0     0      1  \n",
      "2     0     0     0     0     1     0      1  \n",
      "3     0     1     0     1     0     0      1  \n",
      "4     0     0     0     0     1     0      1  \n",
      "\n",
      "[5 rows x 229 columns]\n"
     ]
    }
   ],
   "source": [
    "# We don't need both class columns.  Lets drop one then rename the other to simply 'Class'.\n",
    "df = numerical_df.drop(columns=['Class_-'])\n",
    "\n",
    "df.rename(columns = {'Class_+': 'Class'}, inplace = True)\n",
    "print(df.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model_selection module to separate training and testing datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Create X and Y datasets for training\n",
    "X = np.array(df.drop(['Class'], 1))\n",
    "y = np.array(df['Class'])\n",
    "\n",
    "# define seed for reproducibility\n",
    "seed = 1\n",
    "\n",
    "# split data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors: 0.823214 (0.113908)\n",
      "Test--  Nearest Neighbors :  0.7777777777777778\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        17\n",
      "           1       0.62      1.00      0.77        10\n",
      "\n",
      "    accuracy                           0.78        27\n",
      "   macro avg       0.81      0.82      0.78        27\n",
      "weighted avg       0.86      0.78      0.78        27\n",
      "\n",
      "Gaussian Process: 0.873214 (0.056158)\n",
      "Test--  Gaussian Process :  0.8888888888888888\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        17\n",
      "           1       0.77      1.00      0.87        10\n",
      "\n",
      "    accuracy                           0.89        27\n",
      "   macro avg       0.88      0.91      0.89        27\n",
      "weighted avg       0.91      0.89      0.89        27\n",
      "\n",
      "Decision Tree: 0.773214 (0.164838)\n",
      "Test--  Decision Tree :  0.7777777777777778\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        17\n",
      "           1       0.62      1.00      0.77        10\n",
      "\n",
      "    accuracy                           0.78        27\n",
      "   macro avg       0.81      0.82      0.78        27\n",
      "weighted avg       0.86      0.78      0.78        27\n",
      "\n",
      "Random Forest: 0.594643 (0.156094)\n",
      "Test--  Random Forest :  0.6666666666666666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.59      0.69        17\n",
      "           1       0.53      0.80      0.64        10\n",
      "\n",
      "    accuracy                           0.67        27\n",
      "   macro avg       0.68      0.69      0.66        27\n",
      "weighted avg       0.72      0.67      0.67        27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net: 0.887500 (0.087500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test--  Neural Net :  0.9259259259259259\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        17\n",
      "           1       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.93        27\n",
      "   macro avg       0.92      0.94      0.92        27\n",
      "weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "AdaBoost: 0.912500 (0.112500)\n",
      "Test--  AdaBoost :  0.8518518518518519\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.87        17\n",
      "           1       0.71      1.00      0.83        10\n",
      "\n",
      "    accuracy                           0.85        27\n",
      "   macro avg       0.86      0.88      0.85        27\n",
      "weighted avg       0.89      0.85      0.85        27\n",
      "\n",
      "Naive Bayes: 0.837500 (0.137500)\n",
      "Test--  Naive Bayes :  0.9259259259259259\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        17\n",
      "           1       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.93        27\n",
      "   macro avg       0.92      0.94      0.92        27\n",
      "weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "SVM Linear: 0.850000 (0.108972)\n",
      "Test--  SVM Linear :  0.9629629629629629\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        17\n",
      "           1       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.96        27\n",
      "   macro avg       0.95      0.97      0.96        27\n",
      "weighted avg       0.97      0.96      0.96        27\n",
      "\n",
      "SVM RBF: 0.737500 (0.117925)\n",
      "Test--  SVM RBF :  0.7777777777777778\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        17\n",
      "           1       0.62      1.00      0.77        10\n",
      "\n",
      "    accuracy                           0.78        27\n",
      "   macro avg       0.81      0.82      0.78        27\n",
      "weighted avg       0.86      0.78      0.78        27\n",
      "\n",
      "SVM Sigmoid: 0.569643 (0.159209)\n",
      "Test--  SVM Sigmoid :  0.4444444444444444\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.12      0.21        17\n",
      "           1       0.40      1.00      0.57        10\n",
      "\n",
      "    accuracy                           0.44        27\n",
      "   macro avg       0.70      0.56      0.39        27\n",
      "weighted avg       0.78      0.44      0.34        27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# define scoring method\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Define models to train\n",
    "names = [\"Nearest Neighbors\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"SVM Linear\", \"SVM RBF\", \"SVM Sigmoid\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors = 3),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    SVC(kernel = 'linear'), \n",
    "    SVC(kernel = 'rbf'),\n",
    "    SVC(kernel = 'sigmoid')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state = seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print('Test-- ',name,': ',accuracy_score(y_test, predictions))\n",
    "    print()\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load partSix.py\n",
    "# Neural Networks Demystified\n",
    "# Part 6: Training\n",
    "#\n",
    "# Supporting code for short YouTube series on artificial neural networks.\n",
    "#\n",
    "# Stephen Welch\n",
    "# @stephencwelch\n",
    "\n",
    "\n",
    "## ----------------------- Part 1 ---------------------------- ##\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "## ----------------------- Part 5 ---------------------------- ##\n",
    "\n",
    "class Neural_Network(object):\n",
    "    def __init__(self, layer_i = 2, layer_o = 1, layer_h = 3):        \n",
    "        #Define Hyperparameters\n",
    "        self.inputLayerSize = layer_i\n",
    "        self.outputLayerSize = layer_o\n",
    "        self.hiddenLayerSize = layer_h\n",
    "        \n",
    "        #Weights (parameters)\n",
    "        self.W1 = np.random.randn(self.inputLayerSize,self.hiddenLayerSize)\n",
    "        self.W2 = np.random.randn(self.hiddenLayerSize,self.outputLayerSize)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        #Propogate inputs though network\n",
    "        self.z2 = np.dot(X, self.W1)\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        self.z3 = np.dot(self.a2, self.W2)\n",
    "        yHat = self.sigmoid(self.z3) \n",
    "        return yHat\n",
    "        \n",
    "    def sigmoid(self, z):\n",
    "        #Apply sigmoid activation function to scalar, vector, or matrix\n",
    "        return 1/(1+np.exp(-z))\n",
    "    \n",
    "    def sigmoidPrime(self,z):\n",
    "        #Gradient of sigmoid\n",
    "        return np.exp(-z)/((1+np.exp(-z))**2)\n",
    "    \n",
    "    def costFunction(self, X, y):\n",
    "        #Compute cost for given X,y, use weights already stored in class.\n",
    "        self.yHat = self.forward(X)\n",
    "        J = 0.5*sum((y-self.yHat)**2)\n",
    "        return J\n",
    "        \n",
    "    def costFunctionPrime(self, X, y):\n",
    "        #Compute derivative with respect to W and W2 for a given X and y:\n",
    "        self.yHat = self.forward(X)\n",
    "        \n",
    "        delta3 = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z3))\n",
    "        dJdW2 = np.dot(self.a2.T, delta3)\n",
    "        \n",
    "        delta2 = np.dot(delta3, self.W2.T)*self.sigmoidPrime(self.z2)\n",
    "        dJdW1 = np.dot(X.T, delta2)  \n",
    "        \n",
    "        return dJdW1, dJdW2\n",
    "    \n",
    "    #Helper Functions for interacting with other classes:\n",
    "    def getParams(self):\n",
    "        #Get W1 and W2 unrolled into vector:\n",
    "        params = np.concatenate((self.W1.ravel(), self.W2.ravel()))\n",
    "        return params\n",
    "    \n",
    "    def setParams(self, params):\n",
    "        #Set W1 and W2 using single paramater vector.\n",
    "        W1_start = 0\n",
    "        W1_end = self.hiddenLayerSize * self.inputLayerSize\n",
    "        self.W1 = np.reshape(params[W1_start:W1_end], (self.inputLayerSize , self.hiddenLayerSize))\n",
    "        W2_end = W1_end + self.hiddenLayerSize*self.outputLayerSize\n",
    "        self.W2 = np.reshape(params[W1_end:W2_end], (self.hiddenLayerSize, self.outputLayerSize))\n",
    "        \n",
    "    def computeGradients(self, X, y):\n",
    "        dJdW1, dJdW2 = self.costFunctionPrime(X, y)\n",
    "        return np.concatenate((dJdW1.ravel(), dJdW2.ravel()))\n",
    "\n",
    "def computeNumericalGradient(N, X, y):\n",
    "        paramsInitial = N.getParams()\n",
    "        numgrad = np.zeros(paramsInitial.shape)\n",
    "        perturb = np.zeros(paramsInitial.shape)\n",
    "        e = 1e-4\n",
    "\n",
    "        for p in range(len(paramsInitial)):\n",
    "            #Set perturbation vector\n",
    "            perturb[p] = e\n",
    "            N.setParams(paramsInitial + perturb)\n",
    "            loss2 = N.costFunction(X, y)\n",
    "            \n",
    "            N.setParams(paramsInitial - perturb)\n",
    "            loss1 = N.costFunction(X, y)\n",
    "\n",
    "            #Compute Numerical Gradient\n",
    "            numgrad[p] = (loss2 - loss1) / (2*e)\n",
    "\n",
    "            #Return the value we changed to zero:\n",
    "            perturb[p] = 0\n",
    "            \n",
    "        #Return Params to original value:\n",
    "        N.setParams(paramsInitial)\n",
    "\n",
    "        return numgrad \n",
    "        \n",
    "## ----------------------- Part 6 ---------------------------- ##\n",
    "from scipy import optimize\n",
    "\n",
    "\n",
    "class trainer(object):\n",
    "    def __init__(self, N):\n",
    "        #Make Local reference to network:\n",
    "        self.N = N\n",
    "        \n",
    "    def callbackF(self, params):\n",
    "        self.N.setParams(params)\n",
    "        self.J.append(self.N.costFunction(self.X, self.y))   \n",
    "        \n",
    "    def costFunctionWrapper(self, params, X, y):\n",
    "        self.N.setParams(params)\n",
    "        cost = self.N.costFunction(X, y)\n",
    "        grad = self.N.computeGradients(X,y)\n",
    "        return cost, grad\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        #Make an internal variable for the callback function:\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "        #Make empty list to store costs:\n",
    "        self.J = []\n",
    "        \n",
    "        params0 = self.N.getParams()\n",
    "\n",
    "        options = {'maxiter': 200, 'disp' : True}\n",
    "        _res = optimize.minimize(self.costFunctionWrapper, params0, jac=True, method='BFGS', \\\n",
    "                                 args=(X, y), options=options, callback=self.callbackF)\n",
    "\n",
    "        self.N.setParams(_res.x)\n",
    "        self.optimizationResults = _res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors, test_vectors, train_labels, test_labels = model_selection.train_test_split(X, y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 228)\n",
      "(79,)\n",
      "(27,)\n"
     ]
    }
   ],
   "source": [
    "print(train_vectors.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(79, 1)\n"
     ]
    }
   ],
   "source": [
    "train_labels = train_labels.reshape(79,1)\n",
    "test_labels = test_labels.reshape(27, 1)\n",
    "print(train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 5.249998\n",
      "         Iterations: 11\n",
      "         Function evaluations: 18\n",
      "         Gradient evaluations: 18\n",
      "Training Data error 0.13291135349514457\n",
      "Testing Data error 0.24416594345257464\n"
     ]
    }
   ],
   "source": [
    "#Run the training. \n",
    "NN = Neural_Network(228, 1, 1)\n",
    "T = trainer(NN)\n",
    "T.train(train_vectors, train_labels)\n",
    "\n",
    "pred_labels = NN.forward(train_vectors)\n",
    "print(\"Training Data error\", np.sum((train_labels - pred_labels)*(train_labels-pred_labels))/len(train_vectors))\n",
    "pred_labels = NN.forward(test_vectors)\n",
    "print(\"Testing Data error\", np.sum((test_labels - pred_labels)*(test_labels-pred_labels))/len(test_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000002\n",
      "         Iterations: 52\n",
      "         Function evaluations: 77\n",
      "         Gradient evaluations: 77\n",
      "Training Data error 4.3324210024242e-08\n",
      "Testing Data error 0.03703565933203357\n"
     ]
    }
   ],
   "source": [
    "#Run the training. \n",
    "NN = Neural_Network(228, 1, 4)\n",
    "T = trainer(NN)\n",
    "T.train(train_vectors, train_labels)\n",
    "\n",
    "pred_labels = NN.forward(train_vectors)\n",
    "print(\"Training Data error\", np.sum((train_labels - pred_labels)*(train_labels-pred_labels))/len(train_vectors))\n",
    "pred_labels = NN.forward(test_vectors)\n",
    "print(\"Testing Data error\", np.sum((test_labels - pred_labels)*(test_labels-pred_labels))/len(test_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test-- Artificial Neural Network: 0.9629643406679664\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "print('Test-- Artificial Neural Network:', 1 - np.sum((test_labels - pred_labels)*(test_labels-pred_labels))/len(test_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 5.375009\n",
      "         Iterations: 20\n",
      "         Function evaluations: 35\n",
      "         Gradient evaluations: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaper\\python\\lib\\site-packages\\ipykernel_launcher.py:42: RuntimeWarning: overflow encountered in square\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 1.125009\n",
      "         Iterations: 40\n",
      "         Function evaluations: 61\n",
      "         Gradient evaluations: 61\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.488633\n",
      "         Iterations: 32\n",
      "         Function evaluations: 39\n",
      "         Gradient evaluations: 39\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000001\n",
      "         Iterations: 27\n",
      "         Function evaluations: 31\n",
      "         Gradient evaluations: 31\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000005\n",
      "         Iterations: 38\n",
      "         Function evaluations: 52\n",
      "         Gradient evaluations: 52\n"
     ]
    }
   ],
   "source": [
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "for h in range(1,6):\n",
    "    #initialize the neural network\n",
    "    NN = Neural_Network(228, 1, h)\n",
    "    \n",
    "    # train the model\n",
    "    T = trainer(NN)\n",
    "    T.train(train_vectors, train_labels)\n",
    "    \n",
    "    # make the predictions and calculate accuracy\n",
    "    pred_labels = NN.forward(train_vectors)\n",
    "    train_accuracies.append(1-np.sum((train_labels - pred_labels)*(train_labels-pred_labels))/len(train_vectors))\n",
    "    pred_labels = NN.forward(test_vectors)\n",
    "    test_accuracies.append(1-np.sum((test_labels - pred_labels)*(test_labels-pred_labels))/len(test_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Training Accuracy')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deZxdZZ3n8c83lX2vrEAqSWUhQFDWStgJCYuIDojoCCiKokEhMG1r98iMrT04PbSt7fQYQA0KiAs00jZNKwqBJET2FIGwJCyVvQjZqOwhS1X95o9zApfipupWUrdOLd/361Wvume5937rJHV/9ZznnOdRRGBmZtZQl6wDmJlZ2+QCYWZmeblAmJlZXi4QZmaWlwuEmZnl1TXrAC1lyJAhUV5ennUMM7N25bnnntsYEUPzbeswBaK8vJzKysqsY5iZtSuSVu5vm08xmZlZXi4QZmaWlwuEmZnl5QJhZmZ5uUCYmVleRSsQkm6XtF7Sy/vZLkk/llQl6UVJJ+Rs+4KkN9KvLxQro5mZ7V8xWxB3Auc3sv2jwOHp13TgJwCSBgHfBU4CJgPflVRaxJxmZpZH0e6DiIj5ksob2eUi4K5Ixht/WtJASYcCZwGzI6IGQNJskkJzd7Gymln26uqDV9dupXLFJt7evjvrOO3KIQN6cflJo1r8dbO8UW4EsDpnuTpdt7/1HyBpOknrg1GjWv7gmFnx7Npbx6LVm1mwooYFKzaxcOUmtu2ufXe7lGG4dua4kQM7XIHI988fjaz/4MqIWcAsgIqKCs98ZNaGbd65h8oVm1iwsobKFZt4sXoze+uSX9sjhvfjouMPY1L5ICrKBzFiYK+M0xpkWyCqgZE5y2XAmnT9WQ3Wz2u1VGbWIt7c/A4LltekLYQaXl+3HYBuJeKYsoFcdfpYJpWXcuLoUgb27p5xWssnywLxADBD0j0kHdJbIuItSQ8B/yenY/o84IasQppZ0+rrgzfWb+fZFTVUrqhhwfIa1mzZBUC/Hl05YXQpFx03gorRpRw7ciA9u5VknNgKUbQCIelukpbAEEnVJFcmdQOIiJ8CDwIXAFXATuCL6bYaSd8DFqQvdeO+Dmszaxt219bxUvUWFqzYxIK0KGzdlfQfDO/fg0nlg7i6fBCTygdxxCH9KOniDoX2SMlFRO1fRUVFeDRXs+LYumsvz63clLYONvFC9Wb21NYDMG5oHyaPGUTF6EFMHjOIstJeyD3M7Yak5yKiIt+2DjPct5m1nLVbdr3bd7BgxSZeXbuVCOjaRRw9YgBfOGU0FeWDqBhdyuC+PbKOa0XiAmHWyUUESzdsT04XLa9hwcoaVte8A0Dv7iWcMKqUvzp7ApPKSzlu1EB6d/fHRmfhf2mzTmZvXT0vv7nl3dZB5YoaNu3cC8CQvt2ZVD6IK08dw+TyQRx1aD+6lnjIts7KBcKsg9u+u5bnV6WtgxWbeH71JnbtTfoPygf35pyjhjOpfBCTxgyifHBv9x/Yu1wgzDqY9dt2JTekpX0Ii9dspT6gi+DowwZw2eRR6Q1ppQzr1zPruNaGuUCYtWMRwYq3d77vhrQVb+8EoGe3Lhw/spQZU8czacwgjh9VSt8e/pW3wvl/i1k7UltXz+K3tr7bd7BgxSY2pgPblfbuRkX5IC4/KWkhHH3YALp3df+BHTgXCLM2bOeeWl5YtfndG9IWrtrEzj11AIwc1IszDx9CRfkgJo8pZeyQvnTxDWnWglwgzNqQt7fvpjK9Ie3ZFZt45c0t1NYHEhx5SH8+dWLZu/0Hhw7wgHZWXC4QZhmJCFbXvJNzQ1oNSzfsAKB71y4cVzaQ6WeOZdKYQZwwqpQBvbplnNg6GxcIs1aSOyHOvkHt1m1N+g/69+xKRfkgLjmxjMnlg/hw2QB6dPWAdpYtFwizItl3h/Lsxet5etnb75sQ59ABPTlpzGAmlZcyacwgJgzr5/4Da3NcIMxaUF198NzKTcxevJZHlqxn+cbklNHhw/ryX447jMlp/0FZae+Mk5o1zQXC7CDt3FPL/Nc3MnvxOua8uo5NO/fSrUScMm4IXzp9DOccNcwdytYuuUCYHYD123bx6JL1PLJ4HY9XbWR3bT39e3Zl6pHDOHficKZMGEq/nu5UtvbNBcKsABFB1frtzF6yjtmL1/HC6s1EwIiBvbhs8ijOmzicSWMG0c0D21kH4gJhth+5/QmzF697dwiLD48YwNfPmcC5E4dz5CH9PLiddVguEGY5GutPuOqMse5PsE7FBcI6vX39CbPT/oQ9aX/CtCOHce7EQzhzwhD3J1in5AJhnc6+/oSHF7/XnwBQVtqLz540inMnJvMjuD/BOruiFghJ5wP/DygBfh4R/9hg+2jgdmAoUAN8LiKq023/BHwM6ALMBv5bREQx81rHVVtXn/YnrOORJe/1JxxTNoC/Ptf9CWb5FK1ASCoBbgHOBaqBBZIeiIjFObv9ELgrIn4paRpwE3CFpFOB04Bj0v0eB6YA84qV1zqeHbtr+csbG5i9eP27/QndS7pwyrjB7k8wK0AxWxCTgaqIWAYg6R7gIiC3QEwEvp4+ngvcnz4OoCfQHRDQDVhXxKzWQazfuotHX3V/gllLKGaBGAGszlmuBk5qsM8i4BKS01AXA/0kDY6IpyTNBd4iKRA3R8SShm8gaTowHWDUqFEt/xNYm+f+BLPiKWaByHcyt2EfwjeBmyVdCcwH3gRqJY0HjgLK0v1mSzozIua/78UiZgGzACoqKtw/0Unk9ifMXrKOlTn9Cd84dwLnHj2cI4a7P8HsYBWzQFQDI3OWy4A1uTtExBrgkwCS+gKXRMSWtGXwdERsT7f9CTiZpIhYJ7SvP+HhxeuY++r69/UnfOWMsZxz1HAOGdAz65hmHUoxC8QC4HBJY0haBpcCl+fuIGkIUBMR9cANJFc0AawCviLpJpKWyBTgX4qY1dqg9Vt38ciS9cxevJYnlr7Nntp6BvTqxrQjh3HOUcOZcsRQ+vbwldpmxVK0366IqJU0A3iI5DLX2yPiFUk3ApUR8QBwFnCTpCBpHVybPv0+YBrwEslpqT9HxH8WK6u1DRHBG+u3J6eOcvoTRg7qxedOGs05E4e5P8GsFamj3FpQUVERlZWVWcewZqqtq6dy5SYeadCfcGzZAM45arj7E8yKTNJzEVGRb5vb59bq3J9g1j64QFiraKw/4dyJwzlzgvsTzNoa/0ZaUeT2Jzy8eB2LGvQnJPcnlNLV/QlmbZYLhLWYff0J+8Y7yu1P+OZ5EzhnovsTzNoTFwg7KDt21zL/9Q3J/AmvrWdz2p9w6vjBTD9zLGcf6f4Es/bKBcKabcO23Ty8eC2PLF73vv6Es48cxjnuTzDrMPxbbM2yaccezvu/j7Fp5173J5h1cC4Q1ix3PLGcTTv3cs/0kzlpzCD3J5h1YC4QVrCtu/Zyx5MrOP/oQzh57OCs45hZkfmcgBXsridXsG1XLTOmjc86ipm1AhcIK8iO3bX84vHlnH3kMD40YkDWccysFbhAWEF+88xKNu3c69aDWSfiAmFN2rW3jlnzl3PG4UM4flRp1nHMrJW4QFiT7n52FRu37+a6aYdnHcXMWpELhDVqd20dP3tsGZPHDGLymEFZxzGzVuQCYY2677lq1m7dxfVuPZh1Oi4Qtl976+r5ybylHDdyIKeN930PZp2NC4Tt1/3Pv0n1pne4/uzxvmParBNygbC86uqDW+ct5ejD+jP1iGFZxzGzDLhAWF5/eHENyzfu4Lppbj2YdVZFLRCSzpf0mqQqSd/Ks320pEclvShpnqSynG2jJD0saYmkxZLKi5nV3lNfH9wyt4ojhvfjvImHZB3HzDLSZIGQdI+kj6iZf0ZKKgFuAT4KTAQukzSxwW4/BO6KiGOAG4GbcrbdBfwgIo4CJgPrm/P+duAeemUtr6/bzrXTxtOli1sPZp1VIS2IO4EvAa9L+t+SCh1rYTJQFRHLImIPcA9wUYN9JgKPpo/n7tueFpKuETEbICK2R8TOAt/XDkJEMHNOFWOH9OFjHz406zhmlqEmC0RE/DkiPkPygb8WmCtpvqQrJDU2XPgIYHXOcnW6Ltci4JL08cVAP0mDgQnAZkm/l/S8pB+kLZL3kTRdUqWkyg0bNjT1o1gB5ry6nsVvbeWaqeMpcevBrFMrqA9CUilwOXAF8CLwM+BU4M+NPS3Pumiw/E1giqTngSnAm0AtyTwVZ6TbJwFjgSs/8GIRsyKiIiIqhg4dWsiPYo2ICH48p4qy0l5cdNxhWccxs4wV0gdxL/AkMAi4JCI+FhG/iYivAY3dPVUNjMxZLgPW5O4QEWsi4pMRcTzwP9N1W9LnPp+enqoF7gdOaMbPZQfg8aqNLFq9mWvOGk83Tx9q1ukVMqPcz4HZEdHwr3/SD/b9WQAcLmkMScvgUpJWyLskDQFqIqIeuAG4Pee5pZKGRsQGYBpQWUBWOwgzH63i0AE9ueTEhmcCzawzKuTPxLHAuzPESCqVNL2pJ6V/+c8AHgKWAPdGxCuSbpR0YbrbWcBrkl4HhgP/kD63juT00qOSXiI5XXVbwT+VNdszy97m2RU1XH3mWHp0/UB3j5l1QsrTMHj/DtILEXFcg3XPN9F6aHUVFRVRWelGxoH63M+f4dW123j8v0+lZzcXCLPOQtJzEVGRb1shLYj3fVpI6gJ0a4lg1jYsXLWJx6s2cvWZY10czOxdhfRBzJZ0N/BTkquQvgY8UtRU1qpunlNFae9uXH7SqKyjmFkbUkiB+BvgGuDrJH0BD5Nc5modwMtvbmHOq+v5m48cQZ8ehfx3MLPOoslPhLTDeGb6ZR3MzDlv0L9nV644ZXTWUcysjWmyQEgaR3J10USg5771ETGhiLmsFby2dhsPvbKO688+nP493a1kZu9X6FhMd5CcXvoocC/JuErWzt08t4o+3Uv40mnlWUcxszaokALROyIeAoiIpRHxbWBqcWNZsS3dsJ0/vLiGK04pZ2Dv7lnHMbM2qJBeyd3pUN9LJX2V5K5oTzHWzt06dyk9unbhy2eMyTqKmbVRhRSIrwN9getJ+iL6kwz/be3Uqrd3cv8Lb3LlqeUM6dsj6zhm1kY1WiDSIbYvjohngG0ko7laO/eTx5ZS0kVMP3Ns1lHMrA1rtA8ivcR1citlsVawZvM73Pfcaj5TMZLh/Xs2/QQz67QKOcW0UNLvgd8BO/atjIgHipbKiuZnjy0lAq6e4taDmTWukAIxnKQwXJCzLgAXiHZm/bZd3L1gNZecUEZZae+s45hZG1fIndTud+ggbpu/jNq6eq6ZOi7rKGbWDhRyJ/WsfOsjosk5IazteHv7bn799CouOm4Eowf3yTqOmbUDhZxiejTncU/gYmB1ceJYsdz+xHJ21dZx7dTxWUcxs3aikFNM/5q7LOlXwOyiJbIWt2XnXn755Eou+PChjB/WN+s4ZtZOHMjM9GMAD/3Zjtz55Aq2765lhlsPZtYMhfRBbCK5agmSglIDfKuYoazlbNu1l9ufWM65E4dz1KH9s45jZu1IIX0QQ3Ie10dTk1hbm/Krp1ey5Z29XDfNrQcza55CTjF9DOgbEXUREZIGSvp4IS8u6XxJr0mqkvSBVoek0ZIelfSipHmSyhps7y/pTUk3F/bjWK6de2r5+V+WM2XCUI4pG5h1HDNrZwopEDdGxJZ9CxGxGfheU09Kx3G6hWQOiYnAZZImNtjth8BdEXEMcCNwU4Pt3wMeKyCj5fHbZ1ZRs2MP15/t1oOZNV8hBSLfPoWcmpoMVEXEsojYQzLJ0EUN9pnIe5fRzs3dLulEkru4Hy7gvayBXXvrmDV/GaeMHcyJowdlHcfM2qFCCsRCSf+Ung4aJekHwPMFPG8E779fojpdl2sRcEn6+GKgn6TBkroA/wz8TWNvIGm6pEpJlRs2bCggUufxu8rVrN+2m+vcejCzA1RIgZiR7vcfJOMvBXBNAc9TnnUNO7i/CUyR9DwwhWQyotr09R+MiEZvyIuIWRFREREVQ4cOLSBS57Cntp6fzFvKiaNLOWXs4KzjmFk7VciNcttJPsibqxoYmbNcBqxp8NprgE8CSOoLXBIRWySdApwh6RqSyYq6S9oeEb68tgD//nw1a7bs4v988sMkkwGamTVfky0ISX+WNDBnuVTSHwt47QXA4ZLGSOoOXEqDEWAlDUlPJwHcANwOEBGfjYhREVFOUpzucnEoTG1dPbfMXcoxZQOYMsGtKjM7cIWcYhqeXrkEQERsAg5r6kkRUUtyeuohYAlwb0S8IulGSRemu50FvCbpdZIO6X9oZn5r4IFFa1hVs5MZU8e79WBmB6WQq5HqJZVFRDWApFGFvnhEPAg82GDdd3Ie3wfc18Rr3AncWeh7dmZ19cEtc6s48pB+nDtxeNZxzKydK6RAfAd4QtKcdHkqhXVSWyv708tvsXTDDm65/AS3HszsoBXSSf1HSZOBU0iuTPrvEbG+6MmsWerrg5vnVDFuaB/O/9AhWccxsw6goNFcI2JdRNwPLAS+JGlRcWNZcz2yZB2vrt3GjGnjKeni1oOZHbxCrmIaJmmGpCeB14A+wJXFDmaFiwhmzqli9ODe/Jdjmrx+wMysIPstEJK+KOlh4EmSexhmAG9FxN9FRCF3Ulsrmff6Bl56cwvXnDWOriUHMsWHmdkHNdYHMYukOHx6X0GQ5KG+25iIYOajbzBiYC8uPr6s6SeYmRWosQIxAvgMcEt6o9y/At1aJZUV7Kmlb7Nw1Wa+d9HRdO/q1oOZtZz9fqJExPqImBkRp5IM2b0bqJH0kqQbWy2hNWrmnCqG9evBpytGNr2zmVkzFHoV08qI+MeIOJakVeHLZNqAyhU1PLXsba6eMo6e3UqyjmNmHUwhN8q9T0QsBv6uCFmsmX48p4rBfbpz+eSCb243MyuYT1q3U4tWb2b+6xv48hlj6dXdrQcza3kuEO3UzDlVDOjVjStOGZ11FDProJo8xSTpmDyrtwCrI6K+5SNZUxav2cojS9bx9XMm0LdHs88SmpkVpJBPl18AxwGvkHROHwW8DAyQND0iHm3sydbybplbRb8eXbnytPKso5hZB1bIKaY3gBMj4rj0KqYTgReAj5DMG22tqGr9Nh58+S0+f+poBvTybSlmVjyFFIijIuLFfQsR8RJwQkRUFS+W7c/Nc6ro1a2Eq04fm3UUM+vgCjnFtFTSTOCedPkzQJWkHkBt0ZLZB6zYuIMHFq3hy2eMZVCf7lnHMbMOrpAWxOeBauBbJPNGrwG+QFIczi5eNGvo1nlVdCvpwpfPGJN1FDPrBAqZMGgn8P30q6EtLZ7I8qretJPfL3yTz508mmH9emYdx8w6gUIucz0Z+C4wOnf/iJhQxFzWwE8fW4oE089034OZtY5CTjHdAdwKnAOckfPVJEnnS3pNUpWkb+XZPlrSo5JelDRPUlm6/jhJT0l6Jd32mcJ/pI5n7ZZd3Lugmk+dOJLDBvbKOo6ZdRKFdFJvjYj/bO4LSyoBbgHOJenDWCDpgXQsp31+CNwVEb+UNA24CbgC2Al8PiLekHQY8JykhyJic3NzdASz5i+jLoJrzhqXdRQz60QKKRBzJN0E/J5kyG8Aci993Y/JQFVELAOQdA9wEZBbICYCX08fzwXuT1/79Zz3WSNpPTAU6HQFYuP23fz22ZV84rgRjBzUO+s4ZtaJFFIgTm/wHSCAM5t43ghgdc5yNXBSg30WAZcA/w+4GOgnaXBEvL1vB0mTge7A0oZvIGk6MB1g1KiOOaLpbX9Zxp7aeq6d6taDmbWuQq5iKqi/IY98c0Y0nLL0m8DNkq4E5gNvknNvhaRDgV8BX8g37lNEzCKZGpWKiooONx3qph17+PVTK/n4MYcxdmjfrOOYWSez3wIh6bKIuFvS9fm2R8SPm3jtaiB3mrMyknsocl9jDfDJ9P36ApdExJZ0uT/wR+DbEfF0Uz9IR3THE8vZsaeOa6eOzzqKmXVCjbUgStPvQw/wtRcAh0saQ9IyuBS4PHcHSUOAmrR1cANwe7q+O/DvJB3YvzvA92/Xtu7ayx1PruD8ow/hiEP6ZR3HzDqh/RaIiLg1/X5As8dFRK2kGcBDQAlwe0S8ks5nXRkRDwBnATdJCpJTTNemT/+vJH0cg9PTTwBXRsQLB5KlPbrryRVs21XLjGluPZhZNhTR+Kn79K/8LwHlvP9GuelFTdZMFRUVUVlZmXWMFrFjdy2nf38Ox48q5fYrJ2Udx8w6MEnPRURFvm2FXMX0H8DTwONAXUsGs/x+88xKNu3c69aDmWWqkALRJyK+UfQkBsCuvXXMmr+c08cP4YRRpU0/wcysSAoZauNPks4rehID4O5nV7Fx+26uc+vBzDJWSIH4KvBnSdsl1UjaJKmm2ME6o921dfzssWVMHjOIk8YOzjqOmXVyhZxiGlL0FAbAfc9Vs3brLn7w6WOyjmJm1uiNcodHxBvA0fvZpamxmKwZ9tbV85N5Szlu5EBOH++abGbZa6wF8S3gKpIRWRsqZCwma4b7n3+T6k3v8L8uPBop3yglZmatq7Eb5a5Kvx/oWExWoLr64NZ5Szn6sP5MO3JY1nHMzIDC+iCQdCTJ0NzvznUZEb8tVqjO5g8vrmH5xh389HMnuPVgZm1GIVOOfhs4DziSZNiMj5DcNOcC0QLq64Nb5lYxYXhfzpt4SNZxzMzeVchlrp8BpgJvRcQVwLEU2PKwpj30ylpeX7eda6eOp0sXtx7MrO0opEC8ExF1QK2kfsBaYGxxY3UOEcHMOVWMGdKHjx9zWNZxzMzep5AC8bykgSRDcVcCzwILi5qqk5jz6noWv7WVa84aR4lbD2bWxjR6qkhJj+nfR8Rm4BZJDwH9I8IF4iBFBD+eU0VZaS8+cfyIrOOYmX1Aoy2ISMYC/0POcpWLQ8t4vGoji1Zv5mtnjaNbSSENOTOz1lXIJ9Ozkk4oepJOZuajVRw6oCefOrEs6yhmZnntt0BI2nf66XSSIvGapIWSnpfkVsRBeHrZ2zy7ooarzxxLj64lWccxM8ursT6IZ4ETgE+0UpZO4+Y5VQzp24NLJ4/KOoqZ2X41ViAEEBFLWylLp7Bw1SYer9rI/7jgSHp2c+vBzNquxgrEUEl/vb+NEfGjIuTp8G6eU0Vp72589qTRWUcxM2tUY53UJUBfoN9+vpok6fy076JK0rfybB8t6VFJL0qaJ6ksZ9sXJL2Rfn2hOT9UW/Xym1uY8+p6rjp9DH16+GZ0M2vbGvuUeisibjzQF5ZUQjJU+LlANbBA0gMRsThntx8Cd0XELyVNA24CrpA0CPguUEEytPhz6XM3HWietmDmnDfo17Mrnz+1POsoZmZNaqwFcbC39k4GqiJiWUTsAe4BLmqwz0Tg0fTx3JztHwFmR0RNWhRmA+cfZJ5MvbZ2Gw+9so4vnlpO/57dso5jZtakxgrE2Qf52iOA1TnL1em6XIuAS9LHFwP9JA0u8Lntys1zq+jTvYQvnT4m6yhmZgXZb4GIiJqDfO18LZBosPxNYIqk54EpwJtAbYHPRdJ0SZWSKjds2HCQcYtn6Ybt/OHFNVxxSjkDe3fPOo6ZWUGKOcZDNTAyZ7kMWJO7Q0SsiYhPRsTxwP9M120p5LnpvrMioiIiKoYOHdrS+VvMrXOX0qNrF758hlsPZtZ+FLNALAAOlzRGUnfgUuCB3B0kDZG0L8MNJCPGQjIx0XmSSiWVkkxY9FARsxbNqrd3cv8Lb3L55NEM6dsj6zhmZgUrWoGIiFpgBskH+xLg3oh4RdKNki5MdzsLeE3S68Bw4B/S59YA3yMpMguAG1vglFcmfvLYUkokrp7iKTTMrH0p6sX4EfEg8GCDdd/JeXwfcN9+nns777Uo2qU1m9/hvudW85lJIxnev2fTTzAza0M8znQR/eyxpUTAV6eMyzqKmVmzuUAUyfptu7h7wWo+ecIIykp7Zx3HzKzZXCCK5Lb5y6itq+eas8ZnHcXM7IC4QBTB29t38+unV3HRcSMoH9In6zhmZgfEBaIIbn9iObtq67h2qvsezKz9coFoYVt27uWXT67kgg8dyvhhBQ16a2bWJrlAtLA7nlzO9t21zJjmvgcza99cIFrQtl17ueOJFZxz1HCOOrR/1nHMzA6KC0QL+tXTK9nyzl6uc+vBzDoAF4gWsnNPLT//y3LOnDCUY0cOzDqOmdlBc4FoIb99ZhU1O/ZwvVsPZtZBuEC0gF1765g1fxmnjB1MRfmgrOOYmbUIF4gW8LvK1azfttt9D2bWobhAHKQ9tfX8ZN5SThxdyinjBmcdx8ysxbhAHKTfL6xmzZZdXDdtPFK+mVLNzNonF4iDUFtXz63zlnJM2QCmTGi7U56amR0IF4iD8MCiNayq2cmMqW49mFnH4wJxgOrqg5vnVnHkIf0456jhWccxM2txLhAH6E8vv8WyDTuYMW08Xbq49WBmHY8LxAGorw9unlPFuKF9+OiHDs06jplZURS1QEg6X9JrkqokfSvP9lGS5kp6XtKLki5I13eT9EtJL0laIumGYuZsrkeWrOPVtdu4dup4Stx6MLMOqmgFQlIJcAvwUWAicJmkiQ12+zZwb0QcD1wK3Jqu/zTQIyI+DJwIXC2pvFhZmyMimDmnitGDe3PhsYdlHcfMrGiK2YKYDFRFxLKI2APcA1zUYJ8A9o2LPQBYk7O+j6SuQC9gD7C1iFkLNu/1Dbz05hauOWscXUt8hs7MOq5ifsKNAFbnLFen63L9PfA5SdXAg8B16fr7gB3AW8Aq4IcRUVPErAWJCGY++gYjBvbi4uPLso5jZlZUxSwQ+U7OR4Ply4A7I6IMuAD4laQuJK2POuAwYAzwDUljP/AG0nRJlZIqN2zY0LLp83hq6dssXLWZr04ZS/eubj2YWcdWzE+5amBkznIZ751C2ucq4F6AiHgK6AkMAS4H/hwReyNiPfAEUNHwDSJiVkRURETF0KHFv5P5x3PeYFi/Hny6YmTTO5uZtXPFLBALgMMljZHUnaQT+oEG+6wCzgaQdBRJgdiQrp+mRB/gZODVImZt0oIVNTy9rIbpZ46lZ7eSLKOYmbWKohWIiKgFZgAPAUtIrlZ6RdKNki5Md/sG8BVJi4C7gSsjIkiufuoLvJ/C0c0AAAtESURBVExSaO6IiBeLlbUQM+dUMbhPdy4/aVSWMczMWk3XYr54RDxI0vmcu+47OY8XA6fled52kktd24RFqzcz//UN/O35R9C7e1EPmZlZm+Ge1gLMnFPFgF7duOLk0VlHMTNrNS4QTVi8ZiuPLFnHF08rp1/PblnHMTNrNS4QTbhlbhV9e3Tli6eOyTqKmVmrcoFoRNX6bTz48lt84dTRDOjt1oOZdS4uEI24eU4VPbuW8KXT3Hows87HBWI/VmzcwQOL1vC5k0cxuG+PrOOYmbU6F4j9uHVeFV1LuvCVMz8wwoeZWafgApHH6pqd/H7hm1w2aSTD+vXMOo6ZWSZcIPL42fylSHD1lHFZRzEzy4wLRANrt+zi3gXVfOrEMg4b2CvrOGZmmXGBaGDW/GXURfC1KeOzjmJmlikXiBwbt+/mt8+u5BPHjWDU4N5ZxzEzy5QLRI7b/rKM3bX1XDPVfQ9mZi4QqU079vDrp1by8WMOY9zQvlnHMTPLnAtE6o4nlrNjTx0zprrvwcwMXCAA2LprL3c8uYKPHD2cIw7pl3UcM7M2wQUCuOvJFWzbVct10w7POoqZWZvR6QvEjt21/OLx5Uw9YigfGjEg6zhmZm1Gp58/c/vuWk4ZN5gvn+Exl8zMcnX6AjG8f09u/eyJWccwM2tzinqKSdL5kl6TVCXpW3m2j5I0V9Lzkl6UdEHOtmMkPSXpFUkvSfKoeWZmrahoLQhJJcAtwLlANbBA0gMRsThnt28D90bETyRNBB4EyiV1BX4NXBERiyQNBvYWK6uZmX1QMVsQk4GqiFgWEXuAe4CLGuwTQP/08QBgTfr4PODFiFgEEBFvR0RdEbOamVkDxSwQI4DVOcvV6bpcfw98TlI1SevhunT9BCAkPSRpoaS/LWJOMzPLo5gFQnnWRYPly4A7I6IMuAD4laQuJKe+Tgc+m36/WNLZH3gDabqkSkmVGzZsaNn0ZmadXDELRDUwMme5jPdOIe1zFXAvQEQ8BfQEhqTPfSwiNkbETpLWxQkN3yAiZkVERURUDB06tAg/gplZ51XMArEAOFzSGEndgUuBBxrsswo4G0DSUSQFYgPwEHCMpN5ph/UUYDFmZtZqinYVU0TUSppB8mFfAtweEa9IuhGojIgHgG8At0n6OsnppysjIoBNkn5EUmQCeDAi/lisrGZm9kFKPo/bP0kbgJUH8RJDgI0tFKclOVfzOFfzOFfzdMRcoyMi7zn6DlMgDpakyoioyDpHQ87VPM7VPM7VPJ0tV6cfrM/MzPJzgTAzs7xcIN4zK+sA++FczeNczeNczdOpcrkPwszM8nILwszM8nKBMDOzvDpVgZB0u6T1kl7ez3ZJ+nE6f8WLkj4wvEdGuc6StEXSC+nXd1op18h0vo4l6bwc/y3PPq1+zArM1erHTFJPSc9KWpTm+l959ukh6V/T4/WMpPI2kutKSRtyjteXi50r571L0jlh/pBnW6sfrwIyZXmsVqTz47wgqTLP9pb9fYyITvMFnEkyptPL+9l+AfAnkoEGTwaeaSO5zgL+kMHxOhQ4IX3cD3gdmJj1MSswV6sfs/QY9E0fdwOeAU5usM81wE/Tx5cC/9pGcl0J3Nza/8fS9/5r4Lf5/r2yOF4FZMryWK0AhjSyvUV/HztVCyIi5gM1jexyEXBXJJ4GBko6tA3kykREvBURC9PH24AlfHDI9lY/ZgXmanXpMdieLnZLvxpeBXIR8Mv08X3A2ZLyjXzc2rkyIakM+Bjw8/3s0urHq4BMbVmL/j52qgJRgELmsMjKKekpgj9JOrq13zxt2h9P8tdnrkyPWSO5IINjlp6aeAFYD8yOiP0er4ioBbYAg9tALoBL0tMS90kamWd7MfwL8LdA/X62Z3G8msoE2RwrSAr7w5KekzQ9z/YW/X10gXi/QuawyMJCkvFSjgVmAve35ptL6gv8G/BXEbG14eY8T2mVY9ZErkyOWUTURcRxJMPbT5b0oQa7ZHK8Csj1n0B5RBwDPMJ7f7UXjaSPA+sj4rnGdsuzrmjHq8BMrX6scpwWEScAHwWulXRmg+0terxcIN6vkDksWl1EbN13iiAiHgS6SRrSGu8tqRvJh/BvIuL3eXbJ5Jg1lSvLY5a+52ZgHnB+g03vHi8lQ9kPoBVPL+4vVyTT+u5OF28DTmyFOKcBF0paQTIl8TRJv26wT2sfryYzZXSs9r33mvT7euDfSaZ2ztWiv48uEO/3APD59EqAk4EtEfFW1qEkHbLvvKukyST/bm+3wvsK+AWwJCJ+tJ/dWv2YFZIri2MmaaikgenjXsA5wKsNdnsA+EL6+FPAnEh7F7PM1eA89YUk/TpFFRE3RERZRJSTdEDPiYjPNditVY9XIZmyOFbp+/aR1G/fY+A8oOGVjy36+1i0+SDaIkl3k1zdMkTJPNjfJemwIyJ+SjJz3QVAFbAT+GIbyfUp4GuSaoF3gEuL/aGSOg24AngpPX8N8D+AUTnZsjhmheTK4pgdCvxSUglJQbo3Iv6g98+B8guSqXWrSP4SvrTImQrNdb2kC4HaNNeVrZArrzZwvJrKlNWxGg78e/p3T1fgtxHxZ0lfheL8PnqoDTMzy8unmMzMLC8XCDMzy8sFwszM8nKBMDOzvFwgzMwsLxcIa5ckhaR/zln+pqS/b6HXvlPSp1ritZp4n08rGZF2boP15drPyL5mrckFwtqr3cAnW/Pu6EKk9xoU6irgmoiYWqw8TUnvTjbLywXC2qtaknl4v95wQ8MWgKTt6fezJD0m6V5Jr0v6R0mfVTJXwkuSxuW8zDmS/pLu9/H0+SWSfiBpQTpQ29U5rztX0m+Bl/LkuSx9/ZclfT9d9x3gdOCnkn5QyA8s6Svpey+S9G+SekvqJ2l5OvQIkvormTOgm6Rxkv6sZGC3v0g6Muf4/ChtuXxf0hS9N7fB8/vu1jXzXw/Wnt0CvCjpn5rxnGOBo0jugF0G/DwiJiuZdOg64K/S/cqBKcA4YK6k8cDnSYYumCSpB/CEpIfT/ScDH4qI5blvJukw4Psk4/VsIhmJ8xMRcaOkacA3I+IDE7/sx+8j4rb0df83cFVEzJQ0j2R46vtJ7jT+t4jYK2kW8NWIeEPSScCtwLT0tSYA50REnaT/BK6NiCeUDIC4q8A81sG5BWHtVjqC613A9c142oJ0PondwFJg3wf8SyRFYZ97I6I+It4gKSRHkox98/l0eI9nSIadPjzd/9mGxSE1CZgXERvS4ap/QzJB1IH4UNoSeAn4LLBvCPOf896QCl8E7kg/6E8Ffpfm/RnJkBv7/C4i6tLHTwA/knQ9MDDNaeYWhLV7/0IytPcdOetqSf/4UTJwTfecbbtzHtfnLNfz/t+HhmPQBMlQytdFxEO5GySdBezYT76WnNzmTuATEbFI0pUk43eR/uVfLmkKUBIRL0vqD2xOh/jO5928EfGPkv5IMobP05LOiYiGgwxaJ+QWhLVrEVED3EvS4bvPCt4bgvki0oEPm+nTkrqk/RJjgdeAh0gGANx3vn+CklE1G/MMMEXSkLQD+zLgsQPIA8n0qm+l7//ZBtvuAu4mLZRp62q5pE+nWSXp2HwvKmlcRLwUEd8HKklaS2YuENYh/DOQezXTbSQfys8CJ7H/v+4b8xrJB/mfSM7j7yI5lbMYWJhehvozmmiFp0Mt3wDMBRYBCyPiPwp4/yMkVed8fRr4O5KCM5sPDiP+G6CUpEjs81ngKkmLgFdIimU+f5V2oC8iGfn2TwXks07Ao7madQDpVVsXRcQVWWexjsN9EGbtnKSZJFNQXpB1FutY3IIwM7O83AdhZmZ5uUCYmVleLhBmZpaXC4SZmeXlAmFmZnn9f62ULKXI70TaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = [1,2,3,4,5]\n",
    "plt.plot(layers, train_accuracies)\n",
    "plt.xlabel(\"Number of Layers\")\n",
    "plt.ylabel(\"Training Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Testing Accuracy')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "layers = [1,2,3,4,5]\n",
    "plt.plot(layers, test_accuracies)\n",
    "plt.xlabel(\"Number of Layers\")\n",
    "plt.ylabel(\"Testing Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hmmlearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-519a992ab040>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhmmlearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhmm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# Prepare parameters for a 4-components HMM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Initial population probability\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mstartprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# The transition matrix, note that there are no transitions possible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'hmmlearn'"
     ]
    }
   ],
   "source": [
    "from hmmlearn import hmm\n",
    "# Prepare parameters for a 4-components HMM\n",
    "# Initial population probability\n",
    "startprob = np.array([0.6, 0.3, 0.1, 0.0])\n",
    "# The transition matrix, note that there are no transitions possible\n",
    "# between component 1 and 3\n",
    "transmat = np.array([[0.7, 0.2, 0.0, 0.1],\n",
    "                     [0.3, 0.5, 0.2, 0.0],\n",
    "                     [0.0, 0.3, 0.5, 0.2],\n",
    "                     [0.2, 0.0, 0.2, 0.6]])\n",
    "# The means of each component\n",
    "means = np.array([[0.0,  0.0],\n",
    "                  [0.0, 11.0],\n",
    "                  [9.0, 10.0],\n",
    "                  [11.0, -1.0]])\n",
    "# The covariance of each component\n",
    "covars = .5 * np.tile(np.identity(2), (4, 1, 1))\n",
    "\n",
    "# Build an HMM instance and set parameters\n",
    "model = hmm.GaussianHMM(n_components=4, covariance_type=\"full\")\n",
    "\n",
    "# Instead of fitting it from the data, we directly set the estimated\n",
    "# parameters, the means and covariance of the components\n",
    "model.startprob_ = startprob\n",
    "model.transmat_ = transmat\n",
    "model.means_ = means\n",
    "model.covars_ = covars\n",
    "###############################################################\n",
    "\n",
    "\n",
    "# Plot the sampled data\n",
    "plt.plot(X[:, 0], X[:, 1], \".-\", label=\"observations\", ms=6,\n",
    "         mfc=\"orange\", alpha=0.7)\n",
    "\n",
    "# Indicate the component numbers\n",
    "for i, m in enumerate(means):\n",
    "    plt.text(m[0], m[1], 'Component %i' % (i + 1),\n",
    "             size=17, horizontalalignment='center',\n",
    "             bbox=dict(alpha=.7, facecolor='w'))\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_a</th>\n",
       "      <th>0_c</th>\n",
       "      <th>0_g</th>\n",
       "      <th>0_t</th>\n",
       "      <th>1_a</th>\n",
       "      <th>1_c</th>\n",
       "      <th>1_g</th>\n",
       "      <th>1_t</th>\n",
       "      <th>2_a</th>\n",
       "      <th>2_c</th>\n",
       "      <th>...</th>\n",
       "      <th>54_t</th>\n",
       "      <th>55_a</th>\n",
       "      <th>55_c</th>\n",
       "      <th>55_g</th>\n",
       "      <th>55_t</th>\n",
       "      <th>56_a</th>\n",
       "      <th>56_c</th>\n",
       "      <th>56_g</th>\n",
       "      <th>56_t</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 229 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_a  0_c  0_g  0_t  1_a  1_c  1_g  1_t  2_a  2_c  ...  54_t  55_a  55_c  \\\n",
       "0    0    0    0    1    1    0    0    0    0    1  ...     0     0     0   \n",
       "1    0    0    0    1    0    0    1    0    0    1  ...     0     1     0   \n",
       "2    0    0    1    0    0    0    0    1    1    0  ...     0     0     1   \n",
       "3    1    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
       "4    0    0    0    1    0    1    0    0    0    0  ...     1     1     0   \n",
       "\n",
       "   55_g  55_t  56_a  56_c  56_g  56_t  Class  \n",
       "0     1     0     0     0     0     1      1  \n",
       "1     0     0     1     0     0     0      1  \n",
       "2     0     0     0     0     1     0      1  \n",
       "3     0     1     0     1     0     0      1  \n",
       "4     0     0     0     0     1     0      1  \n",
       "\n",
       "[5 rows x 229 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
