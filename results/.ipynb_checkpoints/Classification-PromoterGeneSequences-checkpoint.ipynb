{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CMSE 410 Project\n",
    "#### Katherine Perry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will go through the kaggle tutorial to load in data from UCI Machine Learning Repository that has 106 DNA sequences, with 57 sequential nucleotides  each. Then I will analyze the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/bulentsiyah/classifying-dna-sequences-markov-models-knn-svm/execution\n",
    "# To make sure all of the correct libraries are installed, import each module and print the version number\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the uci Molecular Biology (Promoter Gene Sequences) Data Set\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/molecular-biology/promoter-gene-sequences/promoters.data'\n",
    "names = ['Class', 'id', 'Sequence']\n",
    "data = pd.read_csv(url, names = names)\n",
    "print(data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['t', 'a', 'c', 't', 'a', 'g', 'c', 'a', 'a', 't', 'a', 'c', 'g', 'c', 't', 't', 'g', 'c', 'g', 't', 't', 'c', 'g', 'g', 't', 'g', 'g', 't', 't', 'a', 'a', 'g', 't', 'a', 't', 'g', 't', 'a', 't', 'a', 'a', 't', 'g', 'c', 'g', 'c', 'g', 'g', 'g', 'c', 't', 't', 'g', 't', 'c', 'g', 't', '+']\n"
     ]
    }
   ],
   "source": [
    "classes = data.loc[:, 'Class']\n",
    "# generate list of DNA sequences\n",
    "sequences = list(data.loc[:, 'Sequence'])\n",
    "dataset = {}\n",
    "\n",
    "# loop through sequences and split into individual nucleotides\n",
    "for i, seq in enumerate(sequences):\n",
    "    \n",
    "    # split into nucleotides, remove tab characters\n",
    "    nucleotides = list(seq)\n",
    "    nucleotides = [x for x in nucleotides if x != '\\t']\n",
    "    \n",
    "    # append class assignment\n",
    "    nucleotides.append(classes[i])\n",
    "    \n",
    "    # add to dataset\n",
    "    dataset[i] = nucleotides\n",
    "    \n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>c</td>\n",
       "      <td>t</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>38</td>\n",
       "      <td>34</td>\n",
       "      <td>33</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9  ...   48   49   50  \\\n",
       "count   106  106  106  106  106  106  106  106  106  106  ...  106  106  106   \n",
       "unique    4    4    4    4    4    4    4    4    4    4  ...    4    4    4   \n",
       "top       t    a    a    c    a    a    a    a    a    a  ...    c    c    c   \n",
       "freq     38   34   30   30   36   42   38   34   33   36  ...   36   42   31   \n",
       "\n",
       "         51   52   53   54   55   56 Class  \n",
       "count   106  106  106  106  106  106   106  \n",
       "unique    4    4    4    4    4    4     2  \n",
       "top       t    t    c    c    c    t     -  \n",
       "freq     33   35   32   29   29   34    53  \n",
       "\n",
       "[4 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn dataset into pandas DataFrame\n",
    "dframe = pd.DataFrame(dataset)\n",
    "# transpose the DataFrame\n",
    "df = dframe.transpose()\n",
    "# for clarity, lets rename the last dataframe column to class\n",
    "df.rename(columns = {57: 'Class'}, inplace = True) \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2     3     4     5     6     7     8     9  ...    48  \\\n",
      "t  38.0  26.0  27.0  26.0  22.0  24.0  30.0  32.0  32.0  28.0  ...  21.0   \n",
      "c  27.0  22.0  21.0  30.0  19.0  18.0  21.0  20.0  22.0  22.0  ...  36.0   \n",
      "a  26.0  34.0  30.0  22.0  36.0  42.0  38.0  34.0  33.0  36.0  ...  23.0   \n",
      "g  15.0  24.0  28.0  28.0  29.0  22.0  17.0  20.0  19.0  20.0  ...  26.0   \n",
      "-   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "+   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  ...   NaN   \n",
      "\n",
      "     49    50    51    52    53    54    55    56  Class  \n",
      "t  22.0  23.0  33.0  35.0  30.0  23.0  29.0  34.0    NaN  \n",
      "c  42.0  31.0  32.0  21.0  32.0  29.0  29.0  17.0    NaN  \n",
      "a  24.0  28.0  27.0  25.0  22.0  26.0  24.0  27.0    NaN  \n",
      "g  18.0  24.0  14.0  25.0  22.0  28.0  24.0  28.0    NaN  \n",
      "-   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   53.0  \n",
      "+   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   53.0  \n",
      "\n",
      "[6 rows x 58 columns]\n"
     ]
    }
   ],
   "source": [
    "# desribe does not tell us enough information since the attributes are text. Lets record value counts for each sequence\n",
    "series = []\n",
    "for name in df.columns:\n",
    "    series.append(df[name].value_counts())\n",
    "    \n",
    "info = pd.DataFrame(series)\n",
    "details = info.transpose()\n",
    "print(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_a</th>\n",
       "      <th>0_c</th>\n",
       "      <th>0_g</th>\n",
       "      <th>0_t</th>\n",
       "      <th>1_a</th>\n",
       "      <th>1_c</th>\n",
       "      <th>1_g</th>\n",
       "      <th>1_t</th>\n",
       "      <th>2_a</th>\n",
       "      <th>2_c</th>\n",
       "      <th>...</th>\n",
       "      <th>55_a</th>\n",
       "      <th>55_c</th>\n",
       "      <th>55_g</th>\n",
       "      <th>55_t</th>\n",
       "      <th>56_a</th>\n",
       "      <th>56_c</th>\n",
       "      <th>56_g</th>\n",
       "      <th>56_t</th>\n",
       "      <th>Class_+</th>\n",
       "      <th>Class_-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 230 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_a  0_c  0_g  0_t  1_a  1_c  1_g  1_t  2_a  2_c  ...  55_a  55_c  55_g  \\\n",
       "0    0    0    0    1    1    0    0    0    0    1  ...     0     0     1   \n",
       "1    0    0    0    1    0    0    1    0    0    1  ...     1     0     0   \n",
       "2    0    0    1    0    0    0    0    1    1    0  ...     0     1     0   \n",
       "3    1    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
       "4    0    0    0    1    0    1    0    0    0    0  ...     1     0     0   \n",
       "\n",
       "   55_t  56_a  56_c  56_g  56_t  Class_+  Class_-  \n",
       "0     0     0     0     0     1        1        0  \n",
       "1     0     1     0     0     0        1        0  \n",
       "2     0     0     0     1     0        1        0  \n",
       "3     1     0     1     0     0        1        0  \n",
       "4     0     0     0     1     0        1        0  \n",
       "\n",
       "[5 rows x 230 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unfortunately, we can't run machine learning algorithms on the data in 'String' formats. As a result, we need to switch\n",
    "# it to numerical data. This can easily be accomplished using the pd.get_dummies() function\n",
    "numerical_df = pd.get_dummies(df)\n",
    "numerical_df.iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0_a  0_c  0_g  0_t  1_a  1_c  1_g  1_t  2_a  2_c  ...  54_t  55_a  55_c  \\\n",
      "0    0    0    0    1    1    0    0    0    0    1  ...     0     0     0   \n",
      "1    0    0    0    1    0    0    1    0    0    1  ...     0     1     0   \n",
      "2    0    0    1    0    0    0    0    1    1    0  ...     0     0     1   \n",
      "3    1    0    0    0    1    0    0    0    0    0  ...     0     0     0   \n",
      "4    0    0    0    1    0    1    0    0    0    0  ...     1     1     0   \n",
      "\n",
      "   55_g  55_t  56_a  56_c  56_g  56_t  Class  \n",
      "0     1     0     0     0     0     1      1  \n",
      "1     0     0     1     0     0     0      1  \n",
      "2     0     0     0     0     1     0      1  \n",
      "3     0     1     0     1     0     0      1  \n",
      "4     0     0     0     0     1     0      1  \n",
      "\n",
      "[5 rows x 229 columns]\n"
     ]
    }
   ],
   "source": [
    "# We don't need both class columns.  Lets drop one then rename the other to simply 'Class'.\n",
    "df = numerical_df.drop(columns=['Class_-'])\n",
    "\n",
    "df.rename(columns = {'Class_+': 'Class'}, inplace = True)\n",
    "print(df.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model_selection module to separate training and testing datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Create X and Y datasets for training\n",
    "X = np.array(df.drop(['Class'], 1))\n",
    "y = np.array(df['Class'])\n",
    "\n",
    "# define seed for reproducibility\n",
    "seed = 1\n",
    "\n",
    "# split data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors: 0.823214 (0.113908)\n",
      "Test--  Nearest Neighbors :  0.7777777777777778\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        17\n",
      "           1       0.62      1.00      0.77        10\n",
      "\n",
      "    accuracy                           0.78        27\n",
      "   macro avg       0.81      0.82      0.78        27\n",
      "weighted avg       0.86      0.78      0.78        27\n",
      "\n",
      "Gaussian Process: 0.873214 (0.056158)\n",
      "Test--  Gaussian Process :  0.8888888888888888\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        17\n",
      "           1       0.77      1.00      0.87        10\n",
      "\n",
      "    accuracy                           0.89        27\n",
      "   macro avg       0.88      0.91      0.89        27\n",
      "weighted avg       0.91      0.89      0.89        27\n",
      "\n",
      "Decision Tree: 0.773214 (0.164838)\n",
      "Test--  Decision Tree :  0.7777777777777778\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        17\n",
      "           1       0.62      1.00      0.77        10\n",
      "\n",
      "    accuracy                           0.78        27\n",
      "   macro avg       0.81      0.82      0.78        27\n",
      "weighted avg       0.86      0.78      0.78        27\n",
      "\n",
      "Random Forest: 0.594643 (0.156094)\n",
      "Test--  Random Forest :  0.6666666666666666\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.59      0.69        17\n",
      "           1       0.53      0.80      0.64        10\n",
      "\n",
      "    accuracy                           0.67        27\n",
      "   macro avg       0.68      0.69      0.66        27\n",
      "weighted avg       0.72      0.67      0.67        27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Net: 0.887500 (0.087500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test--  Neural Net :  0.9259259259259259\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        17\n",
      "           1       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.93        27\n",
      "   macro avg       0.92      0.94      0.92        27\n",
      "weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "AdaBoost: 0.912500 (0.112500)\n",
      "Test--  AdaBoost :  0.8518518518518519\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.76      0.87        17\n",
      "           1       0.71      1.00      0.83        10\n",
      "\n",
      "    accuracy                           0.85        27\n",
      "   macro avg       0.86      0.88      0.85        27\n",
      "weighted avg       0.89      0.85      0.85        27\n",
      "\n",
      "Naive Bayes: 0.837500 (0.137500)\n",
      "Test--  Naive Bayes :  0.9259259259259259\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.88      0.94        17\n",
      "           1       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.93        27\n",
      "   macro avg       0.92      0.94      0.92        27\n",
      "weighted avg       0.94      0.93      0.93        27\n",
      "\n",
      "SVM Linear: 0.850000 (0.108972)\n",
      "Test--  SVM Linear :  0.9629629629629629\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        17\n",
      "           1       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.96        27\n",
      "   macro avg       0.95      0.97      0.96        27\n",
      "weighted avg       0.97      0.96      0.96        27\n",
      "\n",
      "SVM RBF: 0.737500 (0.117925)\n",
      "Test--  SVM RBF :  0.7777777777777778\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.65      0.79        17\n",
      "           1       0.62      1.00      0.77        10\n",
      "\n",
      "    accuracy                           0.78        27\n",
      "   macro avg       0.81      0.82      0.78        27\n",
      "weighted avg       0.86      0.78      0.78        27\n",
      "\n",
      "SVM Sigmoid: 0.569643 (0.159209)\n",
      "Test--  SVM Sigmoid :  0.4444444444444444\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.12      0.21        17\n",
      "           1       0.40      1.00      0.57        10\n",
      "\n",
      "    accuracy                           0.44        27\n",
      "   macro avg       0.70      0.56      0.39        27\n",
      "weighted avg       0.78      0.44      0.34        27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\kaper\\python\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# define scoring method\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Define models to train\n",
    "names = [\"Nearest Neighbors\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"SVM Linear\", \"SVM RBF\", \"SVM Sigmoid\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors = 3),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    SVC(kernel = 'linear'), \n",
    "    SVC(kernel = 'rbf'),\n",
    "    SVC(kernel = 'sigmoid')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state = seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print('Test-- ',name,': ',accuracy_score(y_test, predictions))\n",
    "    print()\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class                                                      EI\n",
      "id                                           ATRINS-DONOR-521\n",
      "Sequence                   CCAGCTGCATCACAGGAGGCCAGCGAGCAGG...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "url2 = \"https://archive.ics.uci.edu/ml/machine-learning-databases/molecular-biology/splice-junction-gene-sequences/splice.data\"\n",
    "names = ['Class', 'id', 'Sequence']\n",
    "data = pd.read_csv(url2, names = names)\n",
    "print(data.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'C', 'C', 'A', 'G', 'C', 'T', 'G', 'C', 'A', 'T', 'C', 'A', 'C', 'A', 'G', 'G', 'A', 'G', 'G', 'C', 'C', 'A', 'G', 'C', 'G', 'A', 'G', 'C', 'A', 'G', 'G', 'T', 'C', 'T', 'G', 'T', 'T', 'C', 'C', 'A', 'A', 'G', 'G', 'G', 'C', 'C', 'T', 'T', 'C', 'G', 'A', 'G', 'C', 'C', 'A', 'G', 'T', 'C', 'T', 'G', 'EI']\n"
     ]
    }
   ],
   "source": [
    "classes = data.loc[:, 'Class']\n",
    "# generate list of DNA sequences\n",
    "sequences = list(data.loc[:, 'Sequence'])\n",
    "dataset = {}\n",
    "\n",
    "# loop through sequences and split into individual nucleotides\n",
    "for i, seq in enumerate(sequences):\n",
    "    \n",
    "    # split into nucleotides, remove tab characters\n",
    "    nucleotides = list(seq)\n",
    "    nucleotides = [x for x in nucleotides if x != '\\t']\n",
    "    \n",
    "    # append class assignment\n",
    "    nucleotides.append(classes[i])\n",
    "    \n",
    "    # add to dataset\n",
    "    dataset[i] = nucleotides\n",
    "    \n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    j = 0\n",
    "    while j < len(dataset[i]):\n",
    "        if dataset[i][j] == ' ':\n",
    "            dataset[i].remove(' ')\n",
    "            j-=1\n",
    "        j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset[0]))\n",
    "print(len(dataset[1]))\n",
    "print(len(dataset[2]))\n",
    "print(len(dataset[3]))\n",
    "print(len(dataset[4]))\n",
    "print(len(dataset[5]))\n",
    "print(len(dataset[6]))\n",
    "print(len(dataset[7]))\n",
    "print(len(dataset[8]))\n",
    "print(len(dataset[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>...</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "      <td>3190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>...</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>876</td>\n",
       "      <td>858</td>\n",
       "      <td>876</td>\n",
       "      <td>884</td>\n",
       "      <td>865</td>\n",
       "      <td>898</td>\n",
       "      <td>858</td>\n",
       "      <td>878</td>\n",
       "      <td>909</td>\n",
       "      <td>849</td>\n",
       "      <td>...</td>\n",
       "      <td>874</td>\n",
       "      <td>874</td>\n",
       "      <td>934</td>\n",
       "      <td>859</td>\n",
       "      <td>838</td>\n",
       "      <td>908</td>\n",
       "      <td>870</td>\n",
       "      <td>860</td>\n",
       "      <td>953</td>\n",
       "      <td>1655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1     2     3     4     5     6     7     8     9  ...    51  \\\n",
       "count   3190  3190  3190  3190  3190  3190  3190  3190  3190  3190  ...  3190   \n",
       "unique     5     5     4     4     4     4     4     4     4     4  ...     5   \n",
       "top        G     C     C     C     C     C     C     C     C     T  ...     G   \n",
       "freq     876   858   876   884   865   898   858   878   909   849  ...   874   \n",
       "\n",
       "          52    53    54    55    56    57    58    59 Class  \n",
       "count   3190  3190  3190  3190  3190  3190  3190  3190  3190  \n",
       "unique     5     5     5     5     5     5     5     5     3  \n",
       "top        G     G     G     G     G     C     C     G     N  \n",
       "freq     874   934   859   838   908   870   860   953  1655  \n",
       "\n",
       "[4 rows x 61 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn dataset into pandas DataFrame\n",
    "dframe = pd.DataFrame(dataset)\n",
    "# transpose the DataFrame\n",
    "df = dframe.transpose()\n",
    "# for clarity, lets rename the last dataframe column to class\n",
    "df.rename(columns = {60: 'Class'}, inplace = True) \n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0      1      2      3      4      5      6      7      8      9  ...  \\\n",
      "G   876.0  794.0  841.0  802.0  719.0  828.0  780.0  731.0  749.0  766.0  ...   \n",
      "C   835.0  858.0  876.0  884.0  865.0  898.0  858.0  878.0  909.0  808.0  ...   \n",
      "A   743.0  779.0  712.0  753.0  801.0  704.0  783.0  790.0  749.0  767.0  ...   \n",
      "T   735.0  758.0  761.0  751.0  805.0  760.0  769.0  791.0  783.0  849.0  ...   \n",
      "D     1.0    1.0    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  ...   \n",
      "N     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  ...   \n",
      "R     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  ...   \n",
      "S     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  ...   \n",
      "IE    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  ...   \n",
      "EI    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN  ...   \n",
      "\n",
      "       51     52     53     54     55     56     57     58     59   Class  \n",
      "G   874.0  874.0  934.0  859.0  838.0  908.0  866.0  789.0  953.0     NaN  \n",
      "C   788.0  832.0  818.0  835.0  831.0  790.0  870.0  860.0  785.0     NaN  \n",
      "A   818.0  733.0  695.0  802.0  756.0  743.0  720.0  785.0  721.0     NaN  \n",
      "T   709.0  750.0  742.0  693.0  763.0  748.0  733.0  755.0  730.0     NaN  \n",
      "D     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN  \n",
      "N     1.0    1.0    1.0    1.0    2.0    1.0    1.0    1.0    1.0  1655.0  \n",
      "R     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN  \n",
      "S     NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN     NaN  \n",
      "IE    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   768.0  \n",
      "EI    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN    NaN   767.0  \n",
      "\n",
      "[10 rows x 61 columns]\n"
     ]
    }
   ],
   "source": [
    "# desribe does not tell us enough information since the attributes are text. Lets record value counts for each sequence\n",
    "series = []\n",
    "for name in df.columns:\n",
    "    series.append(df[name].value_counts())\n",
    "    \n",
    "info = pd.DataFrame(series)\n",
    "details = info.transpose()\n",
    "print(details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_A</th>\n",
       "      <th>0_C</th>\n",
       "      <th>0_D</th>\n",
       "      <th>0_G</th>\n",
       "      <th>0_T</th>\n",
       "      <th>1_A</th>\n",
       "      <th>1_C</th>\n",
       "      <th>1_D</th>\n",
       "      <th>1_G</th>\n",
       "      <th>1_T</th>\n",
       "      <th>...</th>\n",
       "      <th>58_N</th>\n",
       "      <th>58_T</th>\n",
       "      <th>59_A</th>\n",
       "      <th>59_C</th>\n",
       "      <th>59_G</th>\n",
       "      <th>59_N</th>\n",
       "      <th>59_T</th>\n",
       "      <th>Class_EI</th>\n",
       "      <th>Class_IE</th>\n",
       "      <th>Class_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 290 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0_A  0_C  0_D  0_G  0_T  1_A  1_C  1_D  1_G  1_T  ...  58_N  58_T  59_A  \\\n",
       "0    0    1    0    0    0    0    1    0    0    0  ...     0     1     0   \n",
       "1    1    0    0    0    0    0    0    0    1    0  ...     0     0     0   \n",
       "2    0    0    0    1    0    1    0    0    0    0  ...     0     1     0   \n",
       "3    0    0    0    1    0    0    0    0    1    0  ...     0     0     0   \n",
       "4    0    0    0    1    0    0    1    0    0    0  ...     0     0     0   \n",
       "\n",
       "   59_C  59_G  59_N  59_T  Class_EI  Class_IE  Class_N  \n",
       "0     0     1     0     0         1         0        0  \n",
       "1     1     0     0     0         1         0        0  \n",
       "2     0     1     0     0         1         0        0  \n",
       "3     1     0     0     0         1         0        0  \n",
       "4     0     0     0     1         1         0        0  \n",
       "\n",
       "[5 rows x 290 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unfortunately, we can't run machine learning algorithms on the data in 'String' formats. As a result, we need to switch\n",
    "# it to numerical data. This can easily be accomplished using the pd.get_dummies() function\n",
    "numerical_df = pd.get_dummies(df)\n",
    "numerical_df.iloc[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0_A  0_C  0_D  0_G  0_T  1_A  1_C  1_D  1_G  1_T  ...  58_G  58_N  58_T  \\\n",
      "0    0    1    0    0    0    0    1    0    0    0  ...     0     0     1   \n",
      "1    1    0    0    0    0    0    0    0    1    0  ...     1     0     0   \n",
      "2    0    0    0    1    0    1    0    0    0    0  ...     0     0     1   \n",
      "3    0    0    0    1    0    0    0    0    1    0  ...     0     0     0   \n",
      "4    0    0    0    1    0    0    1    0    0    0  ...     0     0     0   \n",
      "\n",
      "   59_A  59_C  59_G  59_N  59_T  Class  Class_IE  \n",
      "0     0     0     1     0     0      1         0  \n",
      "1     0     1     0     0     0      1         0  \n",
      "2     0     0     1     0     0      1         0  \n",
      "3     0     1     0     0     0      1         0  \n",
      "4     0     0     0     0     1      1         0  \n",
      "\n",
      "[5 rows x 289 columns]\n"
     ]
    }
   ],
   "source": [
    "df = numerical_df.drop(columns=['Class_IE'])\n",
    "df = numerical_df.drop(columns=['Class_N'])\n",
    "\n",
    "df.rename(columns = {'Class_EI': 'Class'}, inplace = True)\n",
    "print(df.iloc[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the model_selection module to separate training and testing datasets\n",
    "from sklearn import model_selection\n",
    "\n",
    "# Create X and Y datasets for training\n",
    "X = np.array(df.drop(['Class'], 1))\n",
    "y = np.array(df['Class'])\n",
    "\n",
    "# define seed for reproducibility\n",
    "seed = 1\n",
    "\n",
    "# split data into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.25, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors: 0.881688 (0.020139)\n",
      "Test--  Nearest Neighbors :  0.8834586466165414\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.87      0.92       607\n",
      "           1       0.69      0.92      0.79       191\n",
      "\n",
      "    accuracy                           0.88       798\n",
      "   macro avg       0.83      0.89      0.85       798\n",
      "weighted avg       0.90      0.88      0.89       798\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# define scoring method\n",
    "scoring = 'accuracy'\n",
    "\n",
    "# Define models to train\n",
    "names = [\"Nearest Neighbors\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\", \"SVM Linear\", \"SVM RBF\", \"SVM Sigmoid\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(n_neighbors = 3),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    SVC(kernel = 'linear'), \n",
    "    SVC(kernel = 'rbf'),\n",
    "    SVC(kernel = 'sigmoid')\n",
    "]\n",
    "\n",
    "models = zip(names, classifiers)\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state = seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    print('Test-- ',name,': ',accuracy_score(y_test, predictions))\n",
    "    print()\n",
    "    print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
